"""
LangChain related API routes
"""

from fastapi import APIRouter, HTTPException, status
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

from app.core.config import settings
from app.api.services import get_deepseek_service
from app.api.services.translation_cache_warmer import warmup_translation_cache, get_cache_warm_status
from app.api.services.redis_cache import get_redis_cache
from app.api.services.cache_scheduler import cache_scheduler_service
from app.api.services.scheduler_manager import scheduler_manager

router = APIRouter()


# ============ Request/Response Models ============

class ChatRequest(BaseModel):
    """Chat request model"""
    message: str = Field(..., min_length=1, max_length=4000, description="User message content")
    system_prompt: str | None = Field(None, max_length=2000, description="Optional system prompt")
    temperature: float | None = Field(None, ge=0.0, le=2.0, description="Temperature parameter (0.0-2.0)")
    max_tokens: int | None = Field(None, ge=1, le=4000, description="Maximum tokens")
    stream: bool = Field(False, description="Use streaming response")


class ChatResponse(BaseModel):
    """Chat response model"""
    response: str = Field(..., description="AI response content")
    model: str = Field(..., description="Model name used")


class HealthResponse(BaseModel):
    """Health check response model"""
    status: str = Field(..., description="Service status")
    deepseek_configured: bool = Field(..., description="DeepSeek configuration status")


class ModelInfoResponse(BaseModel):
    """Model information response"""
    model: str
    base_url: str
    configured: bool


class TranslationRequest(BaseModel):
    """Translation request model"""
    text: str = Field(..., min_length=1, max_length=5000, description="Text to translate")
    source_language: str = Field("auto", description="Source language code (e.g., 'en', 'zh', 'auto')")
    target_language: str = Field(..., description="Target language code (e.g., 'en', 'zh')")
    context: str | None = Field(None, max_length=500, description="Optional context for better translation")


class TranslationResponse(BaseModel):
    """Translation response model"""
    translated_text: str = Field(..., description="Translated text")
    source_language: str = Field(..., description="Detected or provided source language")
    target_language: str = Field(..., description="Target language")
    model: str = Field(..., description="Model name used")


class BatchTranslationRequest(BaseModel):
    """Batch translation request model"""
    texts: list[str] = Field(..., min_items=1, max_items=100, description="List of texts to translate")
    source_language: str = Field("auto", description="Source language code (e.g., 'en', 'zh', 'auto')")
    target_language: str = Field(..., description="Target language code (e.g., 'en', 'zh')")
    context: str | None = Field(None, max_length=500, description="Optional context for better translation")


class BatchTranslationResponse(BaseModel):
    """Batch translation response model"""
    translations: list[dict] = Field(..., description="List of translated texts with metadata")
    source_language: str = Field(..., description="Detected or provided source language")
    target_language: str = Field(..., description="Target language")
    model: str = Field(..., description="Model name used")
    total_count: int = Field(..., description="Total number of texts translated")
    success_count: int = Field(..., description="Number of successful translations")


# ============ API Endpoints ============

@router.get(
    "/health",
    response_model=HealthResponse,
    summary="Health Check",
    description="Check LangChain and DeepSeek service status"
)
async def health_check():
    """Health check endpoint"""
    return HealthResponse(
        status="healthy",
        deepseek_configured=bool(settings.DEEPSEEK_API_KEY)
    )


@router.get(
    "/model-info",
    response_model=ModelInfoResponse,
    summary="Get Model Info",
    description="Get current DeepSeek model configuration"
)
async def get_model_info():
    """Get model configuration information"""
    try:
        service = get_deepseek_service()
        info = service.get_model_info()
        return ModelInfoResponse(**info)
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Service not configured: {str(e)}"
        )


@router.post(
    "/chat",
    response_model=ChatResponse,
    summary="AI Chat",
    description="Chat with DeepSeek AI, supports streaming and non-streaming responses"
)
async def chat(request: ChatRequest):
    """
    Chat with DeepSeek AI

    - **message**: User message content (required)
    - **system_prompt**: System prompt (optional)
    - **temperature**: Temperature parameter, controls randomness (optional, 0.0-2.0)
    - **max_tokens**: Maximum tokens (optional)
    - **stream**: Use streaming response (optional, default false)
    """
    if not settings.DEEPSEEK_API_KEY:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="DeepSeek API key not configured"
        )

    try:
        service = get_deepseek_service()

        # Streaming response
        if request.stream:
            async def generate():
                try:
                    async for chunk in service.stream_chat(
                            message=request.message,
                            system_prompt=request.system_prompt
                    ):
                        yield chunk
                except Exception as e:
                    yield f"\n\n[Error: {str(e)}]"

            return StreamingResponse(
                generate(),
                media_type="text/event-stream"
            )

        # Non-streaming response
        response = await service.chat(
            message=request.message,
            system_prompt=request.system_prompt,
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )

        return ChatResponse(
            response=response,
            model=settings.DEEPSEEK_MODEL_NAME
        )

    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Service configuration error: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get response from DeepSeek: {str(e)}"
        )


@router.post(
    "/chat/stream",
    summary="Streaming AI Chat",
    description="Stream chat with DeepSeek AI, returns generated content in real-time"
)
async def chat_stream(request: ChatRequest):
    """
    Streaming chat endpoint

    Returns Server-Sent Events (SSE) format streaming response
    """
    if not settings.DEEPSEEK_API_KEY:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="DeepSeek API key not configured"
        )

    try:
        service = get_deepseek_service()

        async def generate():
            try:
                async for chunk in service.stream_chat(
                        message=request.message,
                        system_prompt=request.system_prompt
                ):
                    # SSE format
                    yield f"data: {chunk}\n\n"

                # Send completion marker
                yield "data: [DONE]\n\n"

            except Exception as e:
                yield f"data: [ERROR: {str(e)}]\n\n"

        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
            }
        )

    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Service configuration error: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to initialize stream: {str(e)}"
        )


@router.post(
    "/translate",
    response_model=TranslationResponse,
    summary="AI Translation",
    description="Translate text using DeepSeek AI with intelligent language detection"
)
async def translate_text(request: TranslationRequest):
    """
    Translate text using DeepSeek AI

    - **text**: Text to translate (required)
    - **source_language**: Source language code (optional, default 'auto' for detection)
    - **target_language**: Target language code (required)
    - **context**: Optional context for better translation (optional)
    """
    if not settings.DEEPSEEK_API_KEY:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="DeepSeek API key not configured"
        )

    try:
        # å°è¯•ä»Redisç¼“å­˜è·å–ç¿»è¯‘
        redis_cache = await get_redis_cache()
        cached_translation = await redis_cache.get_translation(request.text, request.target_language)

        if cached_translation:
            print(f"ğŸ¯ Redisç¼“å­˜å‘½ä¸­: {request.text} -> {cached_translation}")
            return TranslationResponse(
                translated_text=cached_translation,
                source_language=request.source_language if request.source_language != 'auto' else 'detected',
                target_language=request.target_language,
                model=f"{settings.DEEPSEEK_MODEL_NAME} (cached)"
            )

        print(f"ğŸ”„ ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨AIç¿»è¯‘: {request.text}")
        service = get_deepseek_service()

        # æ„å»ºç¿»è¯‘æç¤ºè¯
        language_names = {
            'en': 'English',
            'zh': 'Chinese',
            'ja': 'Japanese',
            'ko': 'Korean',
            'fr': 'French',
            'de': 'German',
            'es': 'Spanish',
            'ru': 'Russian',
            'ar': 'Arabic',
            'pt': 'Portuguese',
            'it': 'Italian',
            'nl': 'Dutch',
            'sv': 'Swedish',
            'da': 'Danish',
            'no': 'Norwegian',
            'fi': 'Finnish',
            'pl': 'Polish',
            'tr': 'Turkish',
            'hi': 'Hindi',
            'th': 'Thai',
            'vi': 'Vietnamese'
        }

        target_lang_name = language_names.get(request.target_language, request.target_language)

        if request.source_language == 'auto':
            system_prompt = f"""You are a professional translator. Your task is to:
1. Detect the source language of the text
2. Translate the text accurately to {target_lang_name}
3. Preserve the original meaning, tone, and context
4. Return ONLY the translated text, no explanations

Format your response as: [DETECTED_LANGUAGE_CODE] TRANSLATED_TEXT
For example: [en] Hello, how are you?"""
        else:
            source_lang_name = language_names.get(request.source_language, request.source_language)
            system_prompt = f"""You are a professional translator. Translate the following text from {source_lang_name} to {target_lang_name}.
Preserve the original meaning, tone, and context.
Return ONLY the translated text, no explanations or extra text."""

        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        context_text = f"\nContext: {request.context}" if request.context else ""
        user_message = f"Text to translate:{context_text}\n\n{request.text}"

        # è°ƒç”¨DeepSeek API
        response = await service.chat(
            message=user_message,
            system_prompt=system_prompt,
            temperature=0.3,  # è¾ƒä½çš„æ¸©åº¦ç¡®ä¿ç¿»è¯‘å‡†ç¡®æ€§
            max_tokens=min(4000, len(request.text) * 2)  # åˆç†çš„tokené™åˆ¶
        )

        # è§£æå“åº”
        response = response.strip()

        if request.source_language == 'auto' and '[' in response and ']' in response:
            # è§£æè¯­è¨€æ£€æµ‹å’Œç¿»è¯‘ç»“æœ
            try:
                lang_end = response.index(']')
                detected_lang = response[1:lang_end].strip()
                translated_text = response[lang_end + 1:].strip()
                source_lang = detected_lang
            except:
                # è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                source_lang = 'unknown'
                translated_text = response
        else:
            source_lang = request.source_language if request.source_language != 'auto' else 'detected'
            translated_text = response

        # ç¼“å­˜ç¿»è¯‘ç»“æœ
        await redis_cache.set_translation(request.text, request.target_language, translated_text)
        print(f"ğŸ’¾ ç¿»è¯‘å·²ç¼“å­˜: {request.text} -> {translated_text}")

        return TranslationResponse(
            translated_text=translated_text,
            source_language=source_lang,
            target_language=request.target_language,
            model=settings.DEEPSEEK_MODEL_NAME
        )

    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Service configuration error: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Translation failed: {str(e)}"
        )


@router.post(
    "/translate/batch",
    response_model=BatchTranslationResponse,
    summary="Batch AI Translation",
    description="Translate multiple texts at once using DeepSeek AI for better performance"
)
async def translate_batch(request: BatchTranslationRequest):
    """Batch translation endpoint for better performance"""
    try:
        service = get_deepseek_service()

        # Prepare context
        context_text = f"\nContext: {request.context}" if request.context else ""

        # Create batch prompt for all texts
        texts_input = "\n".join([f"{i+1}. {text}" for i, text in enumerate(request.texts)])

        system_prompt = f"""You are a professional translator. Translate the following numbered list of texts from {request.source_language} to {request.target_language}.
{context_text}

Requirements:
1. Translate each text accurately while preserving the original meaning and tone
2. Consider the context provided for better translation quality
3. Maintain UI text style - keep it concise and natural
4. Handle placeholders like {{name}} or {{count}} properly - don't translate them
5. Return the results in the same numbered format
6. If a text contains only placeholders or special characters, keep it as is

Example format:
1. [translated text 1]
2. [translated text 2]
3. [translated text 3]

Return ONLY the numbered translations, no explanations."""

        user_message = f"Texts to translate:{context_text}\n\n{texts_input}"

        # Call AI service
        response = await service.chat(
            message=user_message,
            system_prompt=system_prompt,
            temperature=0.3,
            max_tokens=2000
        )

        # Parse batch response
        translations = []
        lines = response.strip().split('\n')
        detected_language = request.source_language if request.source_language != 'auto' else 'detected'

        for i, text in enumerate(request.texts):
            translated_text = text  # Default to original text

            if i < len(lines):
                line = lines[i].strip()
                # Extract text after numbering (e.g., "1. " -> "")
                if '. ' in line:
                    translated_text = line.split('. ', 1)[1]
                elif line and not line.replace('.', '').isdigit():
                    translated_text = line
            else:
                # Fallback: try to find the text in the response
                if f"{i+1}." in response:
                    parts = response.split(f"{i+1}.")
                    if len(parts) > 1:
                        next_part = parts[1].split('\n')[0] if '\n' in parts[1] else parts[1]
                        translated_text = next_part.strip()

            translations.append({
                "original": text,
                "translated": translated_text,
                "index": i
            })

        return BatchTranslationResponse(
            translations=translations,
            source_language=detected_language,
            target_language=request.target_language,
            model=settings.DEEPSEEK_MODEL_NAME,
            total_count=len(request.texts),
            success_count=len([t for t in translations if t["translated"] != t["original"]])
        )

    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Service configuration error: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Batch translation failed: {str(e)}"
        )


# ============ ç¼“å­˜ç®¡ç†ç«¯ç‚¹ ============

class CacheWarmupRequest(BaseModel):
    """ç¼“å­˜é¢„çƒ­è¯·æ±‚"""
    force: bool = Field(False, description="æ˜¯å¦å¼ºåˆ¶é‡æ–°ç¼“å­˜")


class CacheWarmupResponse(BaseModel):
    """ç¼“å­˜é¢„çƒ­å“åº”"""
    success: bool = Field(..., description="é¢„çƒ­æ˜¯å¦æˆåŠŸ")
    stats: dict = Field(..., description="é¢„çƒ­ç»Ÿè®¡ä¿¡æ¯")
    message: str = Field(..., description="å“åº”æ¶ˆæ¯")


class CacheStatusResponse(BaseModel):
    """ç¼“å­˜çŠ¶æ€å“åº”"""
    redis_connected: bool = Field(..., description="Redisè¿æ¥çŠ¶æ€")
    cache_stats: dict = Field(..., description="ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯")
    core_texts_count: int = Field(..., description="æ ¸å¿ƒæ–‡æœ¬æ•°é‡")
    target_languages: int = Field(..., description="ç›®æ ‡è¯­è¨€æ•°é‡")


@router.post(
    "/cache/warmup",
    response_model=CacheWarmupResponse,
    summary="é¢„çƒ­ç¿»è¯‘ç¼“å­˜",
    description="é¢„çƒ­AIç¿»è¯‘ç¼“å­˜åˆ°Redisï¼Œæå‡åç»­ç¿»è¯‘æ€§èƒ½"
)
async def warmup_cache(request: CacheWarmupRequest):
    """é¢„çƒ­ç¿»è¯‘ç¼“å­˜"""
    try:
        stats = await warmup_translation_cache(force=request.force)

        success = stats.get("errors", 0) == 0 and stats.get("languages_processed", 0) > 0

        if success:
            message = f"ç¼“å­˜é¢„çƒ­æˆåŠŸï¼å¤„ç†äº† {stats.get('languages_processed', 0)} ç§è¯­è¨€ï¼Œå…± {stats.get('total_translations', 0)} ä¸ªç¿»è¯‘"
        else:
            message = f"ç¼“å­˜é¢„çƒ­éƒ¨åˆ†å¤±è´¥ã€‚å¤„ç†äº† {stats.get('languages_processed', 0)} ç§è¯­è¨€ï¼Œ{stats.get('errors', 0)} ä¸ªé”™è¯¯"

        return CacheWarmupResponse(
            success=success,
            stats=stats,
            message=message
        )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç¼“å­˜é¢„çƒ­å¤±è´¥: {str(e)}"
        )


@router.get(
    "/cache/status",
    response_model=CacheStatusResponse,
    summary="è·å–ç¼“å­˜çŠ¶æ€",
    description="è·å–Redisç¿»è¯‘ç¼“å­˜çš„çŠ¶æ€å’Œç»Ÿè®¡ä¿¡æ¯"
)
async def get_cache_status():
    """è·å–ç¼“å­˜çŠ¶æ€"""
    try:
        status = await get_cache_warm_status()
        return CacheStatusResponse(**status)

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥: {str(e)}"
        )


@router.delete(
    "/cache/clear",
    summary="æ¸…é™¤ç¼“å­˜",
    description="æ¸…é™¤ç¿»è¯‘ç¼“å­˜"
)
async def clear_cache():
    """æ¸…é™¤ç¿»è¯‘ç¼“å­˜"""
    try:
        redis_cache = await get_redis_cache()
        success = await redis_cache.clear_cache("translation:*")

        if success:
            return {"message": "ç¼“å­˜æ¸…é™¤æˆåŠŸ", "success": True}
        else:
            return {"message": "ç¼“å­˜æ¸…é™¤å¤±è´¥", "success": False}

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ¸…é™¤ç¼“å­˜å¤±è´¥: {str(e)}"
        )


# ============ å®šæ—¶ä»»åŠ¡ç®¡ç†ç«¯ç‚¹ ============

class TaskCreateRequest(BaseModel):
    """åˆ›å»ºå®šæ—¶ä»»åŠ¡è¯·æ±‚"""
    task_id: str = Field(..., description="ä»»åŠ¡ID")
    name: str = Field(..., description="ä»»åŠ¡åç§°")
    interval_hours: int = Field(24, ge=1, le=168, description="æ‰§è¡Œé—´éš”(å°æ—¶)")
    task_type: str = Field("cache_refresh", description="ä»»åŠ¡ç±»å‹")
    enabled: bool = Field(True, description="æ˜¯å¦å¯ç”¨")
    max_retries: int = Field(3, ge=0, le=10, description="æœ€å¤§é‡è¯•æ¬¡æ•°")
    timeout_seconds: int = Field(3600, ge=60, le=7200, description="è¶…æ—¶æ—¶é—´(ç§’)")


class TaskResponse(BaseModel):
    """ä»»åŠ¡å“åº”"""
    id: str = Field(..., description="ä»»åŠ¡ID")
    name: str = Field(..., description="ä»»åŠ¡åç§°")
    enabled: bool = Field(..., description="æ˜¯å¦å¯ç”¨")
    interval_hours: int = Field(..., description="æ‰§è¡Œé—´éš”(å°æ—¶)")
    status: str = Field(..., description="ä»»åŠ¡çŠ¶æ€")
    last_run: str | None = Field(None, description="ä¸Šæ¬¡è¿è¡Œæ—¶é—´")
    next_run: str | None = Field(None, description="ä¸‹æ¬¡è¿è¡Œæ—¶é—´")
    error_count: int = Field(..., description="é”™è¯¯æ¬¡æ•°")
    max_retries: int = Field(..., description="æœ€å¤§é‡è¯•æ¬¡æ•°")


class SchedulerStatusResponse(BaseModel):
    """è°ƒåº¦å™¨çŠ¶æ€å“åº”"""
    scheduler_running: bool = Field(..., description="è°ƒåº¦å™¨æ˜¯å¦è¿è¡Œ")
    total_tasks: int = Field(..., description="æ€»ä»»åŠ¡æ•°")
    enabled_tasks: int = Field(..., description="å¯ç”¨çš„ä»»åŠ¡æ•°")
    tasks: list[TaskResponse] = Field(..., description="ä»»åŠ¡åˆ—è¡¨")


@router.get(
    "/scheduler/status",
    response_model=SchedulerStatusResponse,
    summary="è·å–è°ƒåº¦å™¨çŠ¶æ€",
    description="è·å–å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨çš„çŠ¶æ€å’Œæ‰€æœ‰ä»»åŠ¡ä¿¡æ¯"
)
async def get_scheduler_status():
    """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
    try:
        status = cache_scheduler_service.get_scheduler_status()

        tasks = []
        for task_info in status["tasks_info"]:
            tasks.append(TaskResponse(
                id=task_info["id"],
                name=task_info["name"],
                enabled=task_info["enabled"],
                interval_hours=task_info["interval_hours"],
                status=task_info["status"],
                last_run=task_info["last_run"],
                next_run=task_info["next_run"],
                error_count=task_info["error_count"],
                max_retries=task_info["max_retries"]
            ))

        return SchedulerStatusResponse(
            scheduler_running=status["scheduler_running"],
            total_tasks=status["total_tasks"],
            enabled_tasks=status["enabled_tasks"],
            tasks=tasks
        )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–è°ƒåº¦å™¨çŠ¶æ€å¤±è´¥: {str(e)}"
        )


@router.post(
    "/scheduler/tasks",
    summary="åˆ›å»ºå®šæ—¶ä»»åŠ¡",
    description="åˆ›å»ºæ–°çš„å®šæ—¶ä»»åŠ¡"
)
async def create_scheduled_task(request: TaskCreateRequest):
    """åˆ›å»ºå®šæ—¶ä»»åŠ¡"""
    try:
        success = cache_scheduler_service.add_custom_task(
            task_id=request.task_id,
            name=request.name,
            interval_hours=request.interval_hours,
            task_type=request.task_type,
            enabled=request.enabled,
            max_retries=request.max_retries,
            timeout_seconds=request.timeout_seconds
        )

        if success:
            return {"message": f"å®šæ—¶ä»»åŠ¡ '{request.name}' åˆ›å»ºæˆåŠŸ", "success": True}
        else:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="åˆ›å»ºå®šæ—¶ä»»åŠ¡å¤±è´¥"
            )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºå®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.delete(
    "/scheduler/tasks/{task_id}",
    summary="åˆ é™¤å®šæ—¶ä»»åŠ¡",
    description="åˆ é™¤æŒ‡å®šçš„å®šæ—¶ä»»åŠ¡"
)
async def delete_scheduled_task(task_id: str):
    """åˆ é™¤å®šæ—¶ä»»åŠ¡"""
    try:
        success = scheduler_manager.remove_task(task_id)

        if success:
            return {"message": f"å®šæ—¶ä»»åŠ¡ '{task_id}' åˆ é™¤æˆåŠŸ", "success": True}
        else:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"å®šæ—¶ä»»åŠ¡ '{task_id}' ä¸å­˜åœ¨"
            )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤å®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.post(
    "/scheduler/tasks/{task_id}/enable",
    summary="å¯ç”¨å®šæ—¶ä»»åŠ¡",
    description="å¯ç”¨æŒ‡å®šçš„å®šæ—¶ä»»åŠ¡"
)
async def enable_scheduled_task(task_id: str):
    """å¯ç”¨å®šæ—¶ä»»åŠ¡"""
    try:
        success = scheduler_manager.enable_task(task_id)

        if success:
            return {"message": f"å®šæ—¶ä»»åŠ¡ '{task_id}' å·²å¯ç”¨", "success": True}
        else:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"å®šæ—¶ä»»åŠ¡ '{task_id}' ä¸å­˜åœ¨"
            )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¯ç”¨å®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.post(
    "/scheduler/tasks/{task_id}/disable",
    summary="ç¦ç”¨å®šæ—¶ä»»åŠ¡",
    description="ç¦ç”¨æŒ‡å®šçš„å®šæ—¶ä»»åŠ¡"
)
async def disable_scheduled_task(task_id: str):
    """ç¦ç”¨å®šæ—¶ä»»åŠ¡"""
    try:
        success = scheduler_manager.disable_task(task_id)

        if success:
            return {"message": f"å®šæ—¶ä»»åŠ¡ '{task_id}' å·²ç¦ç”¨", "success": True}
        else:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"å®šæ—¶ä»»åŠ¡ '{task_id}' ä¸å­˜åœ¨"
            )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç¦ç”¨å®šæ—¶ä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.post(
    "/scheduler/tasks/{task_id}/run",
    summary="ç«‹å³æ‰§è¡Œä»»åŠ¡",
    description="ç«‹å³æ‰§è¡ŒæŒ‡å®šçš„å®šæ—¶ä»»åŠ¡"
)
async def run_task_now(task_id: str):
    """ç«‹å³æ‰§è¡Œä»»åŠ¡"""
    try:
        success = scheduler_manager.run_task_now(task_id)

        if success:
            return {"message": f"ä»»åŠ¡ '{task_id}' å·²å¼€å§‹æ‰§è¡Œ", "success": True}
        else:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"ä»»åŠ¡ '{task_id}' ä¸å­˜åœ¨æˆ–æœªå¯ç”¨"
            )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ‰§è¡Œä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.get(
    "/scheduler/tasks/{task_id}",
    summary="è·å–ä»»åŠ¡ä¿¡æ¯",
    description="è·å–æŒ‡å®šå®šæ—¶ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯"
)
async def get_task_info(task_id: str):
    """è·å–ä»»åŠ¡ä¿¡æ¯"""
    try:
        task_info = scheduler_manager.get_task_info(task_id)

        if task_info:
            return task_info
        else:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"ä»»åŠ¡ '{task_id}' ä¸å­˜åœ¨"
            )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä»»åŠ¡ä¿¡æ¯å¤±è´¥: {str(e)}"
        )